{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ab1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score \n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdfbd56",
   "metadata": {},
   "source": [
    "# Loading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "246abfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=pd.read_csv(\"data/BitcoinHeistData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "126357d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              address  year  day  length    weight  count  \\\n",
      "0   111K8kZAEnJg245r2cM6y9zgJGHZtJPy6  2017   11      18  0.008333      1   \n",
      "1  1123pJv8jzeFQaCV4w644pzQJzVWay2zcA  2016  132      44  0.000244      1   \n",
      "2  112536im7hy6wtKbpH1qYDWtTyMRAcA2p7  2016  246       0  1.000000      1   \n",
      "3  1126eDRw2wqSkWosjTCre8cjjQW8sSeWH7  2016  322      72  0.003906      1   \n",
      "4  1129TSjKtx65E35GiUo4AYVeyo48twbrGX  2016  238     144  0.072848    456   \n",
      "\n",
      "   looped  neighbors       income            label  \n",
      "0       0          2  100050000.0  princetonCerber  \n",
      "1       0          1  100000000.0   princetonLocky  \n",
      "2       0          2  200000000.0  princetonCerber  \n",
      "3       0          2   71200000.0  princetonCerber  \n",
      "4       0          1  200000000.0   princetonLocky  \n"
     ]
    }
   ],
   "source": [
    "print(input_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65405481",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffb7a96",
   "metadata": {},
   "source": [
    "#### Checking for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9049e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of duplicates in the Input Data: 0\n"
     ]
    }
   ],
   "source": [
    "print('No of duplicates in the Input Data:',sum(input_data.duplicated()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ccb18b",
   "metadata": {},
   "source": [
    "#### Checking for NaN/null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a8a01b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of NaN/Null values in Input Data: 0\n"
     ]
    }
   ],
   "source": [
    "print('No of NaN/Null values in Input Data:',input_data.isnull().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f473ead",
   "metadata": {},
   "source": [
    "#### Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a469a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              address  year  day  length    weight  count  \\\n",
      "0   111K8kZAEnJg245r2cM6y9zgJGHZtJPy6  2017   11      18  0.008333      1   \n",
      "1  1123pJv8jzeFQaCV4w644pzQJzVWay2zcA  2016  132      44  0.000244      1   \n",
      "2  112536im7hy6wtKbpH1qYDWtTyMRAcA2p7  2016  246       0  1.000000      1   \n",
      "3  1126eDRw2wqSkWosjTCre8cjjQW8sSeWH7  2016  322      72  0.003906      1   \n",
      "4  1129TSjKtx65E35GiUo4AYVeyo48twbrGX  2016  238     144  0.072848    456   \n",
      "\n",
      "   looped  neighbors       income  \n",
      "0       0          2  100050000.0  \n",
      "1       0          1  100000000.0  \n",
      "2       0          2  200000000.0  \n",
      "3       0          2   71200000.0  \n",
      "4       0          1  200000000.0  \n"
     ]
    }
   ],
   "source": [
    "X = input_data.drop(['label'], axis = 1)\n",
    "Y = input_data['label']\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c0063",
   "metadata": {},
   "source": [
    "##### Feature Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c240e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  day  length    weight  count  looped  neighbors       income\n",
      "0  2017   11      18  0.008333      1       0          2  100050000.0\n",
      "1  2016  132      44  0.000244      1       0          1  100000000.0\n",
      "2  2016  246       0  1.000000      1       0          2  200000000.0\n",
      "3  2016  322      72  0.003906      1       0          2   71200000.0\n",
      "4  2016  238     144  0.072848    456       0          1  200000000.0\n"
     ]
    }
   ],
   "source": [
    "# Since the address attribute is irrelevant to the type of Ransomware and including it in X will cause overfitting of the model. Therefore, we can drop this feature\n",
    "X = input_data.drop(['address','label'], axis = 1)\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b1d39a",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bad4998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['montrealAPT' 'montrealComradeCircle' 'montrealCryptConsole'\n",
      " 'montrealCryptXXX' 'montrealCryptoLocker' 'montrealCryptoTorLocker2015'\n",
      " 'montrealDMALocker' 'montrealDMALockerv3' 'montrealEDA2' 'montrealFlyper'\n",
      " 'montrealGlobe' 'montrealGlobeImposter' 'montrealGlobev3'\n",
      " 'montrealJigSaw' 'montrealNoobCrypt' 'montrealRazy' 'montrealSam'\n",
      " 'montrealSamSam' 'montrealVenusLocker' 'montrealWannaCry'\n",
      " 'montrealXLocker' 'montrealXLockerv5.0' 'montrealXTPLocker'\n",
      " 'paduaCryptoWall' 'paduaJigsaw' 'paduaKeRanger' 'princetonCerber'\n",
      " 'princetonLocky' 'white']\n"
     ]
    }
   ],
   "source": [
    "# Transforming non-numerical value in Y to numerical value using label Encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "Y = le.transform(Y)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596989d",
   "metadata": {},
   "source": [
    "#### Normalising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2490363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_n = preprocessing.normalize(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b3ef55",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c65d3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScalar\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler1 = MinMaxScaler().fit(X_n)\n",
    "X_mm = scaler1.transform(X_n)\n",
    "                         \n",
    "# Standard Scaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler2 = StandardScaler().fit(X_n)\n",
    "# X_st = scaler2.transform(X_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3fc4ea",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945eaf5f",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b541c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Accuracy Score on Training Data: 0.9996392323852575\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Accuracy Score on Test Data: 0.9353830277077309\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "n=len(X_mm)//k\n",
    "train_accuracy_scores=[]\n",
    "test_accuracy_scores=[]\n",
    "# Using K-fold cross validation\n",
    "for i in range(k):\n",
    "    X_dummy=copy.deepcopy(X_mm)\n",
    "    Y_dummy=copy.deepcopy(Y)\n",
    "    #Train-test split \n",
    "    \n",
    "    X_test=X_dummy[n*i:n*(i+1)]\n",
    "    Y_test=Y_dummy[n*i:n*(i+1)]\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    if i==0:\n",
    "        X_train=X_dummy[n:]\n",
    "        Y_train=Y_dummy[n:]\n",
    "    else:\n",
    "        X_t=X_dummy[0:n*i]\n",
    "        Y_t=Y_dummy[0:n*i]\n",
    "        X_tt=X_dummy[n*(i+1):]\n",
    "        Y_tt=Y_dummy[n*(i+1):]\n",
    "        X_train=np.concatenate((X_t,X_tt))\n",
    "        Y_train=np.concatenate((Y_t,Y_tt))    \n",
    "    \n",
    "    # model training\n",
    "    clf_D = tree.DecisionTreeClassifier()\n",
    "    clf_D = clf_D.fit(X_train, Y_train)\n",
    "    \n",
    "    #Accuracy calculation\n",
    "    Y_train_pred = clf_D.predict(X_train)\n",
    "    Y_test_pred = clf_D.predict(X_test)\n",
    "    train_accuracy_scores.append(accuracy_score(Y_train, Y_train_pred))\n",
    "    test_accuracy_scores.append(accuracy_score(Y_test, Y_test_pred))\n",
    "print('----------------------------------------------------------------------------------------------------\\n')\n",
    "print('Accuracy Score on Training Data:',np.mean(train_accuracy_scores))\n",
    "print('\\n\\n------------------------------------------------------------------------------------------------\\n')\n",
    "print('Accuracy Score on Test Data:',np.mean(test_accuracy_scores))\n",
    "print('\\n------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0f2f92",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9b0575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------When max_depth = 2  and random state = 0  ---------\n",
      "Accuracy Score on Training Data: 0.9796468402483162\n",
      "Accuracy Score on Test Data: 0.9730125886557665\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------When max_depth = 2  and random state = 1  ---------\n",
      "Accuracy Score on Training Data: 0.9801899836023971\n",
      "Accuracy Score on Test Data: 0.9772597068038396\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------When max_depth = 3  and random state = 0  ---------\n",
      "Accuracy Score on Training Data: 0.9824401339759801\n",
      "Accuracy Score on Test Data: 0.9804234950158263\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------When max_depth = 3  and random state = 1  ---------\n",
      "Accuracy Score on Training Data: 0.9851944298786197\n",
      "Accuracy Score on Test Data: 0.9853235242918484\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------When max_depth = 4  and random state = 0  ---------\n",
      "Accuracy Score on Training Data: 0.9879082824229665\n",
      "Accuracy Score on Test Data: 0.9811546719531687\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------When max_depth = 4  and random state = 1  ---------\n",
      "Accuracy Score on Training Data: 0.989902151745714\n",
      "Accuracy Score on Test Data: 0.9785577074769386\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------When max_depth = 5  and random state = 0  ---------\n",
      "Accuracy Score on Training Data: 0.9907936810313196\n",
      "Accuracy Score on Test Data: 0.9770535688778586\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------When max_depth = 5  and random state = 1  ---------\n",
      "Accuracy Score on Training Data: 0.9914179092335152\n",
      "Accuracy Score on Test Data: 0.9748013999402063\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "k=5\n",
    "n=len(X_mm)//k\n",
    "max_depths=[2,3,4,5]\n",
    "random_states=[0,1]\n",
    "for depth in max_depths:\n",
    "    for state in random_states:\n",
    "        print('\\n\\n\\n----------------------------------------------------------------------------------------------------\\n')\n",
    "        print('----------------------------------------------------------------------------------------------------\\n\\n')\n",
    "        print('----------When max_depth =',depth,' and random state =',state,' ---------')\n",
    "        train_accuracy_scores=[]\n",
    "        test_accuracy_scores=[]\n",
    "        # Using K-fold cross validation\n",
    "        for i in range(k):\n",
    "            X_dummy=copy.deepcopy(X_mm)\n",
    "            Y_dummy=copy.deepcopy(Y)\n",
    "            #Train-test split \n",
    "\n",
    "            X_test=X_dummy[n*i:n*(i+1)]\n",
    "            Y_test=Y_dummy[n*i:n*(i+1)]\n",
    "            X_train\n",
    "            Y_train\n",
    "            if i==0:\n",
    "                X_train=X_dummy[n:]\n",
    "                Y_train=Y_dummy[n:]\n",
    "            else:\n",
    "                X_t=X_dummy[0:n*i]\n",
    "                Y_t=Y_dummy[0:n*i]\n",
    "                X_tt=X_dummy[n*(i+1):]\n",
    "                Y_tt=Y_dummy[n*(i+1):]\n",
    "                X_train=np.concatenate((X_t,X_tt))\n",
    "                Y_train=np.concatenate((Y_t,Y_tt))    \n",
    "\n",
    "            # model training\n",
    "            clf_R = RandomForestClassifier(max_depth=depth, random_state=state)\n",
    "            clf_R = clf_R.fit(X_train, Y_train)\n",
    "\n",
    "            #Accuracy calculation\n",
    "            Y_train_pred = clf_R.predict(X_train)\n",
    "            Y_test_pred = clf_R.predict(X_test)\n",
    "            train_accuracy_scores.append(accuracy_score(Y_train, Y_train_pred))\n",
    "            test_accuracy_scores.append(accuracy_score(Y_test, Y_test_pred))\n",
    "        print('Accuracy Score on Training Data:',np.mean(train_accuracy_scores))\n",
    "        print('Accuracy Score on Test Data:',np.mean(test_accuracy_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf26158c",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "568763b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Accuracy Score on Training Data: 0.9858014072422663\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Accuracy Score on Test Data: 0.9858013950721622\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "k=5\n",
    "n=len(X_mm)//k\n",
    "train_accuracy_scores=[]\n",
    "test_accuracy_scores=[]\n",
    "# Using K-fold cross validation\n",
    "for i in range(k):\n",
    "    X_dummy=copy.deepcopy(X_mm)\n",
    "    Y_dummy=copy.deepcopy(Y)\n",
    "    #Train-test split \n",
    "    \n",
    "    X_test=X_dummy[n*i:n*(i+1)]\n",
    "    Y_test=Y_dummy[n*i:n*(i+1)]\n",
    "    X_train\n",
    "    Y_train\n",
    "    if i==0:\n",
    "        X_train=X_dummy[n:]\n",
    "        Y_train=Y_dummy[n:]\n",
    "    else:\n",
    "        X_t=X_dummy[0:n*i]\n",
    "        Y_t=Y_dummy[0:n*i]\n",
    "        X_tt=X_dummy[n*(i+1):]\n",
    "        Y_tt=Y_dummy[n*(i+1):]\n",
    "        X_train=np.concatenate((X_t,X_tt))\n",
    "        Y_train=np.concatenate((Y_t,Y_tt))    \n",
    "    \n",
    "    # model training\n",
    "    clf_N = MultinomialNB()\n",
    "    clf_N = clf_N.fit(X_train, Y_train)\n",
    "    \n",
    "    #Accuracy calculation\n",
    "    Y_train_pred = clf_N.predict(X_train)\n",
    "    Y_test_pred = clf_N.predict(X_test)\n",
    "    train_accuracy_scores.append(accuracy_score(Y_train, Y_train_pred))\n",
    "    test_accuracy_scores.append(accuracy_score(Y_test, Y_test_pred))\n",
    "print('----------------------------------------------------------------------------------------------------\\n')\n",
    "print('Accuracy Score on Training Data:',np.mean(train_accuracy_scores))\n",
    "print('\\n\\n------------------------------------------------------------------------------------------------\\n')\n",
    "print('Accuracy Score on Test Data:',np.mean(test_accuracy_scores))\n",
    "print('\\n------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dafd15",
   "metadata": {},
   "source": [
    "## KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56ee12f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------When we have  2  nearest neighbours ---------\n",
      "Accuracy Score on Training Data: 0.9632180389416014\n",
      "Accuracy Score on Test Data: 0.9551857569571339\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------When we have  3  nearest neighbours ---------\n",
      "Accuracy Score on Training Data: 0.9728231856804006\n",
      "Accuracy Score on Test Data: 0.9615643830943675\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------When we have  4  nearest neighbours ---------\n",
      "Accuracy Score on Training Data: 0.9733624540701200\n",
      "Accuracy Score on Test Data: 0.9570979596664613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k=2\n",
    "n=len(X_mm)//k\n",
    "nearest_neighbours=[2,3,4]\n",
    "for neighbour in nearest_neighbours:\n",
    "    print('\\n\\n\\n----------------------------------------------------------------------------------------------------\\n')\n",
    "    print('----------------------------------------------------------------------------------------------------\\n\\n')\n",
    "    print('----------When we have ',neighbour,' nearest neighbours ---------')\n",
    "    train_accuracy_scores=[]\n",
    "    test_accuracy_scores=[]\n",
    "    # Using K-fold cross validation\n",
    "    for i in range(k):\n",
    "        X_dummy=copy.deepcopy(X_mm)\n",
    "        Y_dummy=copy.deepcopy(Y)\n",
    "        #Train-test split \n",
    "\n",
    "        X_test=X_dummy[n*i:n*(i+1)]\n",
    "        Y_test=Y_dummy[n*i:n*(i+1)]\n",
    "        X_train\n",
    "        Y_train\n",
    "        if i==0:\n",
    "            X_train=X_dummy[n:]\n",
    "            Y_train=Y_dummy[n:]\n",
    "        else:\n",
    "            X_t=X_dummy[0:n*i]\n",
    "            Y_t=Y_dummy[0:n*i]\n",
    "            X_tt=X_dummy[n*(i+1):]\n",
    "            Y_tt=Y_dummy[n*(i+1):]\n",
    "            X_train=np.concatenate((X_t,X_tt))\n",
    "            Y_train=np.concatenate((Y_t,Y_tt))    \n",
    "\n",
    "        # model training\n",
    "        clf_K = KNeighborsClassifier(n_neighbors=neighbour)\n",
    "        clf_K = clf_K.fit(X_train, Y_train)\n",
    "\n",
    "        #Accuracy calculation\n",
    "        Y_train_pred = clf_K.predict(X_train)\n",
    "        Y_test_pred = clf_K.predict(X_test)\n",
    "        train_accuracy_scores.append(accuracy_score(Y_train, Y_train_pred))\n",
    "        test_accuracy_scores.append(accuracy_score(Y_test, Y_test_pred))\n",
    "    print('Accuracy Score on Training Data:',np.mean(train_accuracy_scores))\n",
    "    print('Accuracy Score on Test Data:',np.mean(test_accuracy_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
